{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c990201-9fd1-47ed-92ae-fec393adaf82",
   "metadata": {},
   "source": [
    "Необходимо решить задачу классификации на основе датасета рукописных символов EMNIST и оформить модель как сервис. Таким образом, решение состоит из следующих шагов:\r\n",
    "\r\n",
    "Подготовка данных, построение, обучение и тестирование модели.\r\n",
    "Обёртка готовой модели в сервис, запуск веб-приложения в Docker-контейнере, подготовка репозитория.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cb7bbc2-eaec-4f6b-b98b-0644870faf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install tqdm\n",
    "#!pip install torch torchvision torchinfo\n",
    "#!pip install -U scikit-image matplotlib numpy\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "239aaa14-3962-49d6-a4ac-faddfe175a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import emnist\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import EMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fa0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#датасет уже скачан и находится в директории data/\n",
    "#dataset = EMNIST('data/', 'balanced', download=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "170974aa-54cc-4ad1-92f6-92452d56ec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 112800 samples\n",
      "Test: 18800 samples\n",
      "Image size: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "images_train, labels_train = emnist.extract_training_samples('balanced')\n",
    "images_test, labels_test = emnist.extract_test_samples('balanced')\n",
    "\n",
    "#количество семплов в каждом сплите датасета и размер изображений\n",
    "print(f'Train: {len(images_train)} samples')\n",
    "print(f'Test: {len(images_test)} samples')\n",
    "print(f'Image size: {images_train[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7711da06-1ead-4448-9ac4-82bf10fe2113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0, Символ: 0, Кол-во семплов: 2400\n",
      "label: 1, Символ: 1, Кол-во семплов: 2400\n",
      "label: 2, Символ: 2, Кол-во семплов: 2400\n",
      "label: 3, Символ: 3, Кол-во семплов: 2400\n",
      "label: 4, Символ: 4, Кол-во семплов: 2400\n",
      "label: 5, Символ: 5, Кол-во семплов: 2400\n",
      "label: 6, Символ: 6, Кол-во семплов: 2400\n",
      "label: 7, Символ: 7, Кол-во семплов: 2400\n",
      "label: 8, Символ: 8, Кол-во семплов: 2400\n",
      "label: 9, Символ: 9, Кол-во семплов: 2400\n",
      "label: 10, Символ: A, Кол-во семплов: 2400\n",
      "label: 11, Символ: B, Кол-во семплов: 2400\n",
      "label: 12, Символ: C, Кол-во семплов: 2400\n",
      "label: 13, Символ: D, Кол-во семплов: 2400\n",
      "label: 14, Символ: E, Кол-во семплов: 2400\n",
      "label: 15, Символ: F, Кол-во семплов: 2400\n",
      "label: 16, Символ: G, Кол-во семплов: 2400\n",
      "label: 17, Символ: H, Кол-во семплов: 2400\n",
      "label: 18, Символ: I, Кол-во семплов: 2400\n",
      "label: 19, Символ: J, Кол-во семплов: 2400\n",
      "label: 20, Символ: K, Кол-во семплов: 2400\n",
      "label: 21, Символ: L, Кол-во семплов: 2400\n",
      "label: 22, Символ: M, Кол-во семплов: 2400\n",
      "label: 23, Символ: N, Кол-во семплов: 2400\n",
      "label: 24, Символ: O, Кол-во семплов: 2400\n",
      "label: 25, Символ: P, Кол-во семплов: 2400\n",
      "label: 26, Символ: Q, Кол-во семплов: 2400\n",
      "label: 27, Символ: R, Кол-во семплов: 2400\n",
      "label: 28, Символ: S, Кол-во семплов: 2400\n",
      "label: 29, Символ: T, Кол-во семплов: 2400\n",
      "label: 30, Символ: U, Кол-во семплов: 2400\n",
      "label: 31, Символ: V, Кол-во семплов: 2400\n",
      "label: 32, Символ: W, Кол-во семплов: 2400\n",
      "label: 33, Символ: X, Кол-во семплов: 2400\n",
      "label: 34, Символ: Y, Кол-во семплов: 2400\n",
      "label: 35, Символ: Z, Кол-во семплов: 2400\n",
      "label: 36, Символ: a, Кол-во семплов: 2400\n",
      "label: 37, Символ: b, Кол-во семплов: 2400\n",
      "label: 38, Символ: d, Кол-во семплов: 2400\n",
      "label: 39, Символ: e, Кол-во семплов: 2400\n",
      "label: 40, Символ: f, Кол-во семплов: 2400\n",
      "label: 41, Символ: g, Кол-во семплов: 2400\n",
      "label: 42, Символ: h, Кол-во семплов: 2400\n",
      "label: 43, Символ: n, Кол-во семплов: 2400\n",
      "label: 44, Символ: q, Кол-во семплов: 2400\n",
      "label: 45, Символ: r, Кол-во семплов: 2400\n",
      "label: 46, Символ: t, Кол-во семплов: 2400\n"
     ]
    }
   ],
   "source": [
    "# создаем словарь соответствий mapping\n",
    "with open('emnist-balanced-mapping.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "mapping = {int(line.split()[0]): chr(int(line.split()[1])) for line in lines}\n",
    "\n",
    "images_train, labels_train = emnist.extract_training_samples('balanced')\n",
    "\n",
    "characters = [mapping[label] for label in labels_train]\n",
    "\n",
    "char_counts = pd.Series(characters).value_counts()\n",
    "\n",
    "for label, symbol in mapping.items():\n",
    "    count = char_counts[symbol] if symbol in char_counts else 0\n",
    "    print(f\"label: {label}, Символ: {symbol}, Кол-во семплов: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe17e19-a052-49c1-9d9b-38930da4eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping сохраняем в ф-л mapping.pkl\n",
    "with open(os.path.join('myapp', 'mapping.pkl'),'wb') as f:\n",
    "    pickle.dump(mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "006f8b21-87fe-43ad-b636-5fc4418d1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим в тензоры\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    #Normalize([0.5], [0.5])\n",
    "    Normalize([0.1307], [0.3081])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.EMNIST('data/', split='balanced', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.EMNIST('data/', split='balanced', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fff7cc-bc7e-44dd-9f1e-53ced4d7092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2d - это слой (layer) в библиотеке PyTorch 2D свёртки\n",
    "#параметры слоя Conv2d включают:\n",
    "# in_channels: количество каналов входящего изображения.\n",
    "# out_channels: количество выходных каналов (то есть количество ядер свёртки).\n",
    "# kernel_size: размер ядра свёртки (например, 3x3, 5x5 и т.д.).\n",
    "# stride: шаг свёртки (по умолчанию равен 1).\n",
    "# padding: тип паддинга (валидный или полный, по умолчанию \"валидный\").\n",
    "# dilation: значение разреженности (по умолчанию равно 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8cd43d86-df1d-4212-857f-8c52f5d741a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,  # свертка на вход приходит ч.б. изображение-1канал  (цветное 3канала)\n",
    "                      out_channels=32, \n",
    "                      kernel_size=3,\n",
    "                      padding=1),                   \n",
    "            nn.ReLU(),                  # делаем активацию функцией ReLU\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2), # MaxPool2d уменьшаем кол-во параметров (кол-во признаков/4) \n",
    "\n",
    "            # + слой Conv2d для дилатации dilation=2\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2),\n",
    "            #nn.ReLU(),\n",
    "            #nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Flatten(),# вытягиваем в вектор\n",
    "# предиктор...слой 6272признаков (28х28)х32/4 (MaxPool2d) на вход\n",
    "            nn.Linear(in_features=6272, out_features=64), # задаем кол-во скрытых признаков out_features=128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128), # задаем кол-во скрытых признаков out_features=128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=n_classes) # предскажем кол-во классов out_features=n_classes net = CNN(47)\n",
    "         )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "758b4bcb-18cf-4bfc-9814-7c65d6766ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [1, 47]                   --\n",
       "├─Sequential: 1-1                        [1, 47]                   --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─ReLU: 2-2                         [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-3                    [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 14, 14]           9,248\n",
       "│    └─ReLU: 2-5                         [1, 32, 14, 14]           --\n",
       "│    └─Flatten: 2-6                      [1, 6272]                 --\n",
       "│    └─Linear: 2-7                       [1, 64]                   401,472\n",
       "│    └─ReLU: 2-8                         [1, 64]                   --\n",
       "│    └─Linear: 2-9                       [1, 128]                  8,320\n",
       "│    └─ReLU: 2-10                        [1, 128]                  --\n",
       "│    └─Linear: 2-11                      [1, 47]                   6,063\n",
       "==========================================================================================\n",
       "Total params: 425,423\n",
       "Trainable params: 425,423\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.25\n",
       "Params size (MB): 1.70\n",
       "Estimated Total Size (MB): 1.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!!!!!!!!!эту ячейку надо запускать перед предиктором (закоментировать) тогда посчитает кол-во признаков 6272\n",
    "net = CNN(47)\n",
    "summary(net, input_size=(1, 1, 28, 28))# 1 - количество батчей (batch size), 1 - количество каналов (channels), 28х28 размер высота ширина\n",
    "#после повторного запуска видим в конце вектор из 47 предсказаний Linear: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4cb1a73c-6866-4479-9cf0-1d04c99c81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0\n",
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader)\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_val_accuracy}')\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "            loss_sum += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Val Loss: {loss_sum / len(val_loader):.6f} \\tValidation Accuracy: {accuracy:.4f}')\n",
    "    # Обновление лучшей точности, если текущая точность выше\n",
    "    global best_val_accuracy\n",
    "    if accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9d5b9f99-1daf-477b-9024-0088d0df8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iter: 0 \tLoss: 3.855135202407837\n",
      "Iter: 10 \tLoss: 3.4655778408050537\n",
      "Iter: 20 \tLoss: 2.40836238861084\n",
      "Iter: 30 \tLoss: 1.9041616916656494\n",
      "Iter: 40 \tLoss: 1.5570290088653564\n",
      "Iter: 50 \tLoss: 1.3128650188446045\n",
      "Iter: 60 \tLoss: 1.3744773864746094\n",
      "Iter: 70 \tLoss: 1.2651950120925903\n",
      "Iter: 80 \tLoss: 1.2173404693603516\n",
      "Iter: 90 \tLoss: 1.0791014432907104\n",
      "Iter: 100 \tLoss: 0.8800034523010254\n",
      "Iter: 110 \tLoss: 1.058297872543335\n",
      "Iter: 120 \tLoss: 0.9136370420455933\n",
      "Iter: 130 \tLoss: 0.9420478343963623\n",
      "Iter: 140 \tLoss: 0.8949120044708252\n",
      "Iter: 150 \tLoss: 0.8345274925231934\n",
      "Iter: 160 \tLoss: 0.8368244767189026\n",
      "Iter: 170 \tLoss: 0.8335728049278259\n",
      "Iter: 180 \tLoss: 0.7723187804222107\n",
      "Iter: 190 \tLoss: 0.6936318874359131\n",
      "Iter: 200 \tLoss: 0.612078845500946\n",
      "Iter: 210 \tLoss: 0.5953605771064758\n",
      "Iter: 220 \tLoss: 0.6610121130943298\n",
      "Iter: 230 \tLoss: 0.6432927250862122\n",
      "Iter: 240 \tLoss: 0.5330628156661987\n",
      "Iter: 250 \tLoss: 0.6346298456192017\n",
      "Iter: 260 \tLoss: 0.5780438184738159\n",
      "Iter: 270 \tLoss: 0.6641591787338257\n",
      "Iter: 280 \tLoss: 0.671129047870636\n",
      "Iter: 290 \tLoss: 0.6369562149047852\n",
      "Iter: 300 \tLoss: 0.6327465176582336\n",
      "Iter: 310 \tLoss: 0.5509657263755798\n",
      "Iter: 320 \tLoss: 0.6338695883750916\n",
      "Iter: 330 \tLoss: 0.569490909576416\n",
      "Iter: 340 \tLoss: 0.69522625207901\n",
      "Iter: 350 \tLoss: 0.5846716165542603\n",
      "Iter: 360 \tLoss: 0.516405463218689\n",
      "Iter: 370 \tLoss: 0.5741825103759766\n",
      "Iter: 380 \tLoss: 0.5981482863426208\n",
      "Iter: 390 \tLoss: 0.6178982853889465\n",
      "Iter: 400 \tLoss: 0.4349595308303833\n",
      "Iter: 410 \tLoss: 0.4042927324771881\n",
      "Iter: 420 \tLoss: 0.4939863681793213\n",
      "Iter: 430 \tLoss: 0.5245257616043091\n",
      "Iter: 440 \tLoss: 0.5144219994544983\n",
      "Mean Train Loss: 0.926018\n",
      "\n",
      "Val Loss: 0.542135 \tValidation Accuracy: 0.8218\n",
      "Epoch: 1\n",
      "Iter: 0 \tLoss: 0.44466039538383484\n",
      "Iter: 10 \tLoss: 0.39477255940437317\n",
      "Iter: 20 \tLoss: 0.3820874094963074\n",
      "Iter: 30 \tLoss: 0.4759252667427063\n",
      "Iter: 40 \tLoss: 0.3779352009296417\n",
      "Iter: 50 \tLoss: 0.5323383212089539\n",
      "Iter: 60 \tLoss: 0.41973185539245605\n",
      "Iter: 70 \tLoss: 0.5110585689544678\n",
      "Iter: 80 \tLoss: 0.46601372957229614\n",
      "Iter: 90 \tLoss: 0.6283131241798401\n",
      "Iter: 100 \tLoss: 0.4327472448348999\n",
      "Iter: 110 \tLoss: 0.5032370090484619\n",
      "Iter: 120 \tLoss: 0.40182578563690186\n",
      "Iter: 130 \tLoss: 0.5213856101036072\n",
      "Iter: 140 \tLoss: 0.4041830599308014\n",
      "Iter: 150 \tLoss: 0.3879166841506958\n",
      "Iter: 160 \tLoss: 0.4421224892139435\n",
      "Iter: 170 \tLoss: 0.42625606060028076\n",
      "Iter: 180 \tLoss: 0.5054861307144165\n",
      "Iter: 190 \tLoss: 0.45097342133522034\n",
      "Iter: 200 \tLoss: 0.465950608253479\n",
      "Iter: 210 \tLoss: 0.53289794921875\n",
      "Iter: 220 \tLoss: 0.4192155599594116\n",
      "Iter: 230 \tLoss: 0.3966262936592102\n",
      "Iter: 240 \tLoss: 0.48527348041534424\n",
      "Iter: 250 \tLoss: 0.3977019488811493\n",
      "Iter: 260 \tLoss: 0.47650638222694397\n",
      "Iter: 270 \tLoss: 0.41606616973876953\n",
      "Iter: 280 \tLoss: 0.42746081948280334\n",
      "Iter: 290 \tLoss: 0.4300360381603241\n",
      "Iter: 300 \tLoss: 0.49192380905151367\n",
      "Iter: 310 \tLoss: 0.4705636203289032\n",
      "Iter: 320 \tLoss: 0.467497318983078\n",
      "Iter: 330 \tLoss: 0.6112693548202515\n",
      "Iter: 340 \tLoss: 0.3758299648761749\n",
      "Iter: 350 \tLoss: 0.450223833322525\n",
      "Iter: 360 \tLoss: 0.4241245687007904\n",
      "Iter: 370 \tLoss: 0.3939213454723358\n",
      "Iter: 380 \tLoss: 0.42862990498542786\n",
      "Iter: 390 \tLoss: 0.36858704686164856\n",
      "Iter: 400 \tLoss: 0.4261475205421448\n",
      "Iter: 410 \tLoss: 0.3993043303489685\n",
      "Iter: 420 \tLoss: 0.4481872022151947\n",
      "Iter: 430 \tLoss: 0.5162290930747986\n",
      "Iter: 440 \tLoss: 0.46395620703697205\n",
      "Mean Train Loss: 0.459266\n",
      "\n",
      "Epoch: 2\n",
      "Iter: 0 \tLoss: 0.41380006074905396\n",
      "Iter: 10 \tLoss: 0.4734414219856262\n",
      "Iter: 20 \tLoss: 0.3179878294467926\n",
      "Iter: 30 \tLoss: 0.3712261915206909\n",
      "Iter: 40 \tLoss: 0.331084281206131\n",
      "Iter: 50 \tLoss: 0.41466817259788513\n",
      "Iter: 60 \tLoss: 0.35482144355773926\n",
      "Iter: 70 \tLoss: 0.4810590445995331\n",
      "Iter: 80 \tLoss: 0.3635295033454895\n",
      "Iter: 90 \tLoss: 0.2747827172279358\n",
      "Iter: 100 \tLoss: 0.4512972831726074\n",
      "Iter: 110 \tLoss: 0.3540295958518982\n",
      "Iter: 120 \tLoss: 0.4716980457305908\n",
      "Iter: 130 \tLoss: 0.3392627239227295\n",
      "Iter: 140 \tLoss: 0.35227376222610474\n",
      "Iter: 150 \tLoss: 0.4650106132030487\n",
      "Iter: 160 \tLoss: 0.45662274956703186\n",
      "Iter: 170 \tLoss: 0.35351118445396423\n",
      "Iter: 180 \tLoss: 0.3683723509311676\n",
      "Iter: 190 \tLoss: 0.3060228228569031\n",
      "Iter: 200 \tLoss: 0.34634339809417725\n",
      "Iter: 210 \tLoss: 0.3341714143753052\n",
      "Iter: 220 \tLoss: 0.3010413646697998\n",
      "Iter: 230 \tLoss: 0.3137996792793274\n",
      "Iter: 240 \tLoss: 0.3638181686401367\n",
      "Iter: 250 \tLoss: 0.3472217321395874\n",
      "Iter: 260 \tLoss: 0.41412052512168884\n",
      "Iter: 270 \tLoss: 0.3080624043941498\n",
      "Iter: 280 \tLoss: 0.38500314950942993\n",
      "Iter: 290 \tLoss: 0.47928234934806824\n",
      "Iter: 300 \tLoss: 0.4042276442050934\n",
      "Iter: 310 \tLoss: 0.454035222530365\n",
      "Iter: 320 \tLoss: 0.43453744053840637\n",
      "Iter: 330 \tLoss: 0.33533233404159546\n",
      "Iter: 340 \tLoss: 0.36275026202201843\n",
      "Iter: 350 \tLoss: 0.41670122742652893\n",
      "Iter: 360 \tLoss: 0.3943544030189514\n",
      "Iter: 370 \tLoss: 0.2885594069957733\n",
      "Iter: 380 \tLoss: 0.38261929154396057\n",
      "Iter: 390 \tLoss: 0.3826252520084381\n",
      "Iter: 400 \tLoss: 0.4342819154262543\n",
      "Iter: 410 \tLoss: 0.31308209896087646\n",
      "Iter: 420 \tLoss: 0.37580618262290955\n",
      "Iter: 430 \tLoss: 0.48615196347236633\n",
      "Iter: 440 \tLoss: 0.2651199996471405\n",
      "Mean Train Loss: 0.387555\n",
      "\n",
      "Val Loss: 0.422857 \tValidation Accuracy: 0.8548\n",
      "Epoch: 3\n",
      "Iter: 0 \tLoss: 0.2774287760257721\n",
      "Iter: 10 \tLoss: 0.31882748007774353\n",
      "Iter: 20 \tLoss: 0.29886341094970703\n",
      "Iter: 30 \tLoss: 0.28219160437583923\n",
      "Iter: 40 \tLoss: 0.37220343947410583\n",
      "Iter: 50 \tLoss: 0.46639785170555115\n",
      "Iter: 60 \tLoss: 0.3001804053783417\n",
      "Iter: 70 \tLoss: 0.3516325354576111\n",
      "Iter: 80 \tLoss: 0.3302933871746063\n",
      "Iter: 90 \tLoss: 0.2970394492149353\n",
      "Iter: 100 \tLoss: 0.3130322992801666\n",
      "Iter: 110 \tLoss: 0.3794206380844116\n",
      "Iter: 120 \tLoss: 0.27281126379966736\n",
      "Iter: 130 \tLoss: 0.3380281925201416\n",
      "Iter: 140 \tLoss: 0.37329888343811035\n",
      "Iter: 150 \tLoss: 0.3028210401535034\n",
      "Iter: 160 \tLoss: 0.2704128921031952\n",
      "Iter: 170 \tLoss: 0.3222983181476593\n",
      "Iter: 180 \tLoss: 0.31808191537857056\n",
      "Iter: 190 \tLoss: 0.33282119035720825\n",
      "Iter: 200 \tLoss: 0.45401209592819214\n",
      "Iter: 210 \tLoss: 0.4102872908115387\n",
      "Iter: 220 \tLoss: 0.369822233915329\n",
      "Iter: 230 \tLoss: 0.37235164642333984\n",
      "Iter: 240 \tLoss: 0.4498397409915924\n",
      "Iter: 250 \tLoss: 0.39203622937202454\n",
      "Iter: 260 \tLoss: 0.32598623633384705\n",
      "Iter: 270 \tLoss: 0.31039270758628845\n",
      "Iter: 280 \tLoss: 0.3623642027378082\n",
      "Iter: 290 \tLoss: 0.33341071009635925\n",
      "Iter: 300 \tLoss: 0.2564155161380768\n",
      "Iter: 310 \tLoss: 0.4104105532169342\n",
      "Iter: 320 \tLoss: 0.2790566086769104\n",
      "Iter: 330 \tLoss: 0.3503058850765228\n",
      "Iter: 340 \tLoss: 0.3505062758922577\n",
      "Iter: 350 \tLoss: 0.29652243852615356\n",
      "Iter: 360 \tLoss: 0.4000931978225708\n",
      "Iter: 370 \tLoss: 0.3412778973579407\n",
      "Iter: 380 \tLoss: 0.36601442098617554\n",
      "Iter: 390 \tLoss: 0.3964329957962036\n",
      "Iter: 400 \tLoss: 0.26177725195884705\n",
      "Iter: 410 \tLoss: 0.3813452422618866\n",
      "Iter: 420 \tLoss: 0.47316327691078186\n",
      "Iter: 430 \tLoss: 0.31013020873069763\n",
      "Iter: 440 \tLoss: 0.3425215482711792\n",
      "Mean Train Loss: 0.345948\n",
      "\n",
      "Epoch: 4\n",
      "Iter: 0 \tLoss: 0.3403489291667938\n",
      "Iter: 10 \tLoss: 0.2756008505821228\n",
      "Iter: 20 \tLoss: 0.3924995958805084\n",
      "Iter: 30 \tLoss: 0.3013096749782562\n",
      "Iter: 40 \tLoss: 0.328350305557251\n",
      "Iter: 50 \tLoss: 0.3675535023212433\n",
      "Iter: 60 \tLoss: 0.26135313510894775\n",
      "Iter: 70 \tLoss: 0.2850269079208374\n",
      "Iter: 80 \tLoss: 0.30146777629852295\n",
      "Iter: 90 \tLoss: 0.2556630074977875\n",
      "Iter: 100 \tLoss: 0.37737414240837097\n",
      "Iter: 110 \tLoss: 0.29132264852523804\n",
      "Iter: 120 \tLoss: 0.3182164132595062\n",
      "Iter: 130 \tLoss: 0.36137840151786804\n",
      "Iter: 140 \tLoss: 0.28117141127586365\n",
      "Iter: 150 \tLoss: 0.26609006524086\n",
      "Iter: 160 \tLoss: 0.3007581830024719\n",
      "Iter: 170 \tLoss: 0.30482083559036255\n",
      "Iter: 180 \tLoss: 0.2720779478549957\n",
      "Iter: 190 \tLoss: 0.2522636651992798\n",
      "Iter: 200 \tLoss: 0.24574945867061615\n",
      "Iter: 210 \tLoss: 0.33586588501930237\n",
      "Iter: 220 \tLoss: 0.353606641292572\n",
      "Iter: 230 \tLoss: 0.3412171006202698\n",
      "Iter: 240 \tLoss: 0.33951306343078613\n",
      "Iter: 250 \tLoss: 0.3058980703353882\n",
      "Iter: 260 \tLoss: 0.3299165666103363\n",
      "Iter: 270 \tLoss: 0.29395201802253723\n",
      "Iter: 280 \tLoss: 0.23746821284294128\n",
      "Iter: 290 \tLoss: 0.2770441174507141\n",
      "Iter: 300 \tLoss: 0.3774779140949249\n",
      "Iter: 310 \tLoss: 0.2394132763147354\n",
      "Iter: 320 \tLoss: 0.36760392785072327\n",
      "Iter: 330 \tLoss: 0.31775346398353577\n",
      "Iter: 340 \tLoss: 0.25515031814575195\n",
      "Iter: 350 \tLoss: 0.3001900613307953\n",
      "Iter: 360 \tLoss: 0.3580859303474426\n",
      "Iter: 370 \tLoss: 0.33333346247673035\n",
      "Iter: 380 \tLoss: 0.2848975956439972\n",
      "Iter: 390 \tLoss: 0.3704349398612976\n",
      "Iter: 400 \tLoss: 0.33203986287117004\n",
      "Iter: 410 \tLoss: 0.2181386947631836\n",
      "Iter: 420 \tLoss: 0.26074424386024475\n",
      "Iter: 430 \tLoss: 0.21633034944534302\n",
      "Iter: 440 \tLoss: 0.34687742590904236\n",
      "Mean Train Loss: 0.316325\n",
      "\n",
      "Val Loss: 0.379928 \tValidation Accuracy: 0.8698\n",
      "Epoch: 5\n",
      "Iter: 0 \tLoss: 0.2629530429840088\n",
      "Iter: 10 \tLoss: 0.2625329792499542\n",
      "Iter: 20 \tLoss: 0.25391703844070435\n",
      "Iter: 30 \tLoss: 0.27567458152770996\n",
      "Iter: 40 \tLoss: 0.34332138299942017\n",
      "Iter: 50 \tLoss: 0.33560025691986084\n",
      "Iter: 60 \tLoss: 0.24700236320495605\n",
      "Iter: 70 \tLoss: 0.2691851854324341\n",
      "Iter: 80 \tLoss: 0.32388097047805786\n",
      "Iter: 90 \tLoss: 0.2295762300491333\n",
      "Iter: 100 \tLoss: 0.2824515998363495\n",
      "Iter: 110 \tLoss: 0.2531246542930603\n",
      "Iter: 120 \tLoss: 0.2274741530418396\n",
      "Iter: 130 \tLoss: 0.3461298644542694\n",
      "Iter: 140 \tLoss: 0.2728048861026764\n",
      "Iter: 150 \tLoss: 0.2854708135128021\n",
      "Iter: 160 \tLoss: 0.2160337269306183\n",
      "Iter: 170 \tLoss: 0.25797367095947266\n",
      "Iter: 180 \tLoss: 0.2828829288482666\n",
      "Iter: 190 \tLoss: 0.34641554951667786\n",
      "Iter: 200 \tLoss: 0.32309257984161377\n",
      "Iter: 210 \tLoss: 0.2846338152885437\n",
      "Iter: 220 \tLoss: 0.3053647577762604\n",
      "Iter: 230 \tLoss: 0.3552880585193634\n",
      "Iter: 240 \tLoss: 0.29628878831863403\n",
      "Iter: 250 \tLoss: 0.33655932545661926\n",
      "Iter: 260 \tLoss: 0.2388029247522354\n",
      "Iter: 270 \tLoss: 0.25495612621307373\n",
      "Iter: 280 \tLoss: 0.2582091987133026\n",
      "Iter: 290 \tLoss: 0.31502172350883484\n",
      "Iter: 300 \tLoss: 0.2328576147556305\n",
      "Iter: 310 \tLoss: 0.30989333987236023\n",
      "Iter: 320 \tLoss: 0.2834075689315796\n",
      "Iter: 330 \tLoss: 0.26242801547050476\n",
      "Iter: 340 \tLoss: 0.3009170889854431\n",
      "Iter: 350 \tLoss: 0.29204514622688293\n",
      "Iter: 360 \tLoss: 0.3827933967113495\n",
      "Iter: 370 \tLoss: 0.2706648111343384\n",
      "Iter: 380 \tLoss: 0.375858873128891\n",
      "Iter: 390 \tLoss: 0.3097057640552521\n",
      "Iter: 400 \tLoss: 0.3508215844631195\n",
      "Iter: 410 \tLoss: 0.2615910768508911\n",
      "Iter: 420 \tLoss: 0.3307863771915436\n",
      "Iter: 430 \tLoss: 0.2465660125017166\n",
      "Iter: 440 \tLoss: 0.3065643012523651\n",
      "Mean Train Loss: 0.294726\n",
      "\n",
      "Epoch: 6\n",
      "Iter: 0 \tLoss: 0.4033372402191162\n",
      "Iter: 10 \tLoss: 0.24442148208618164\n",
      "Iter: 20 \tLoss: 0.2111506313085556\n",
      "Iter: 30 \tLoss: 0.21160189807415009\n",
      "Iter: 40 \tLoss: 0.26619067788124084\n",
      "Iter: 50 \tLoss: 0.24342215061187744\n",
      "Iter: 60 \tLoss: 0.24234381318092346\n",
      "Iter: 70 \tLoss: 0.251015305519104\n",
      "Iter: 80 \tLoss: 0.22989286482334137\n",
      "Iter: 90 \tLoss: 0.29383257031440735\n",
      "Iter: 100 \tLoss: 0.19238506257534027\n",
      "Iter: 110 \tLoss: 0.34402135014533997\n",
      "Iter: 120 \tLoss: 0.3201000690460205\n",
      "Iter: 130 \tLoss: 0.21114039421081543\n",
      "Iter: 140 \tLoss: 0.2314186990261078\n",
      "Iter: 150 \tLoss: 0.2640531361103058\n",
      "Iter: 160 \tLoss: 0.27282604575157166\n",
      "Iter: 170 \tLoss: 0.30913883447647095\n",
      "Iter: 180 \tLoss: 0.271182656288147\n",
      "Iter: 190 \tLoss: 0.32740285992622375\n",
      "Iter: 200 \tLoss: 0.19487135112285614\n",
      "Iter: 210 \tLoss: 0.259875625371933\n",
      "Iter: 220 \tLoss: 0.3210309147834778\n",
      "Iter: 230 \tLoss: 0.3337327539920807\n",
      "Iter: 240 \tLoss: 0.2346177101135254\n",
      "Iter: 250 \tLoss: 0.3739561438560486\n",
      "Iter: 260 \tLoss: 0.23157541453838348\n",
      "Iter: 270 \tLoss: 0.34319329261779785\n",
      "Iter: 280 \tLoss: 0.2726409137248993\n",
      "Iter: 290 \tLoss: 0.2136707603931427\n",
      "Iter: 300 \tLoss: 0.3175148367881775\n",
      "Iter: 310 \tLoss: 0.286185622215271\n",
      "Iter: 320 \tLoss: 0.2368917018175125\n",
      "Iter: 330 \tLoss: 0.2648579776287079\n",
      "Iter: 340 \tLoss: 0.3117583990097046\n",
      "Iter: 350 \tLoss: 0.27854326367378235\n",
      "Iter: 360 \tLoss: 0.21737240254878998\n",
      "Iter: 370 \tLoss: 0.31364455819129944\n",
      "Iter: 380 \tLoss: 0.21975299715995789\n",
      "Iter: 390 \tLoss: 0.24777205288410187\n",
      "Iter: 400 \tLoss: 0.30554690957069397\n",
      "Iter: 410 \tLoss: 0.30475062131881714\n",
      "Iter: 420 \tLoss: 0.2862485945224762\n",
      "Iter: 430 \tLoss: 0.27088698744773865\n",
      "Iter: 440 \tLoss: 0.29740798473358154\n",
      "Mean Train Loss: 0.274616\n",
      "\n",
      "Val Loss: 0.389423 \tValidation Accuracy: 0.8652\n",
      "Epoch: 7\n",
      "Iter: 0 \tLoss: 0.27673545479774475\n",
      "Iter: 10 \tLoss: 0.18172448873519897\n",
      "Iter: 20 \tLoss: 0.20791514217853546\n",
      "Iter: 30 \tLoss: 0.20194296538829803\n",
      "Iter: 40 \tLoss: 0.26597896218299866\n",
      "Iter: 50 \tLoss: 0.25310274958610535\n",
      "Iter: 60 \tLoss: 0.2469995617866516\n",
      "Iter: 70 \tLoss: 0.25620871782302856\n",
      "Iter: 80 \tLoss: 0.19197474420070648\n",
      "Iter: 90 \tLoss: 0.23942653834819794\n",
      "Iter: 100 \tLoss: 0.289723664522171\n",
      "Iter: 110 \tLoss: 0.24174997210502625\n",
      "Iter: 120 \tLoss: 0.2640096843242645\n",
      "Iter: 130 \tLoss: 0.22390197217464447\n",
      "Iter: 140 \tLoss: 0.2549467086791992\n",
      "Iter: 150 \tLoss: 0.22429831326007843\n",
      "Iter: 160 \tLoss: 0.2726927399635315\n",
      "Iter: 170 \tLoss: 0.1956011801958084\n",
      "Iter: 180 \tLoss: 0.27487003803253174\n",
      "Iter: 190 \tLoss: 0.2765015959739685\n",
      "Iter: 200 \tLoss: 0.28855177760124207\n",
      "Iter: 210 \tLoss: 0.2844933867454529\n",
      "Iter: 220 \tLoss: 0.32276204228401184\n",
      "Iter: 230 \tLoss: 0.18049503862857819\n",
      "Iter: 240 \tLoss: 0.2985081374645233\n",
      "Iter: 250 \tLoss: 0.27479174733161926\n",
      "Iter: 260 \tLoss: 0.2807064950466156\n",
      "Iter: 270 \tLoss: 0.2766630947589874\n",
      "Iter: 280 \tLoss: 0.2975354790687561\n",
      "Iter: 290 \tLoss: 0.3120634853839874\n",
      "Iter: 300 \tLoss: 0.24940544366836548\n",
      "Iter: 310 \tLoss: 0.28336429595947266\n",
      "Iter: 320 \tLoss: 0.2698952555656433\n",
      "Iter: 330 \tLoss: 0.2804619073867798\n",
      "Iter: 340 \tLoss: 0.3105843663215637\n",
      "Iter: 350 \tLoss: 0.2057362049818039\n",
      "Iter: 360 \tLoss: 0.24043585360050201\n",
      "Iter: 370 \tLoss: 0.2319549024105072\n",
      "Iter: 380 \tLoss: 0.25804510712623596\n",
      "Iter: 390 \tLoss: 0.30799901485443115\n",
      "Iter: 400 \tLoss: 0.2280024141073227\n",
      "Iter: 410 \tLoss: 0.24068975448608398\n",
      "Iter: 420 \tLoss: 0.3083133101463318\n",
      "Iter: 430 \tLoss: 0.2704673111438751\n",
      "Iter: 440 \tLoss: 0.2732955813407898\n",
      "Mean Train Loss: 0.254081\n",
      "\n",
      "Epoch: 8\n",
      "Iter: 0 \tLoss: 0.2728952169418335\n",
      "Iter: 10 \tLoss: 0.22317028045654297\n",
      "Iter: 20 \tLoss: 0.22106720507144928\n",
      "Iter: 30 \tLoss: 0.2240705043077469\n",
      "Iter: 40 \tLoss: 0.34161144495010376\n",
      "Iter: 50 \tLoss: 0.25576022267341614\n",
      "Iter: 60 \tLoss: 0.23596754670143127\n",
      "Iter: 70 \tLoss: 0.18574084341526031\n",
      "Iter: 80 \tLoss: 0.20660825073719025\n",
      "Iter: 90 \tLoss: 0.2697727382183075\n",
      "Iter: 100 \tLoss: 0.17401312291622162\n",
      "Iter: 110 \tLoss: 0.17162267863750458\n",
      "Iter: 120 \tLoss: 0.21704694628715515\n",
      "Iter: 130 \tLoss: 0.2561851441860199\n",
      "Iter: 140 \tLoss: 0.1916658729314804\n",
      "Iter: 150 \tLoss: 0.2690703272819519\n",
      "Iter: 160 \tLoss: 0.2766854763031006\n",
      "Iter: 170 \tLoss: 0.2706952393054962\n",
      "Iter: 180 \tLoss: 0.24367637932300568\n",
      "Iter: 190 \tLoss: 0.2405628263950348\n",
      "Iter: 200 \tLoss: 0.28470396995544434\n",
      "Iter: 210 \tLoss: 0.21868090331554413\n",
      "Iter: 220 \tLoss: 0.27694493532180786\n",
      "Iter: 230 \tLoss: 0.1828370839357376\n",
      "Iter: 240 \tLoss: 0.18472523987293243\n",
      "Iter: 250 \tLoss: 0.2500953674316406\n",
      "Iter: 260 \tLoss: 0.2078157216310501\n",
      "Iter: 270 \tLoss: 0.18897253274917603\n",
      "Iter: 280 \tLoss: 0.2857629060745239\n",
      "Iter: 290 \tLoss: 0.28824955224990845\n",
      "Iter: 300 \tLoss: 0.2274002879858017\n",
      "Iter: 310 \tLoss: 0.25770658254623413\n",
      "Iter: 320 \tLoss: 0.23837712407112122\n",
      "Iter: 330 \tLoss: 0.26528438925743103\n",
      "Iter: 340 \tLoss: 0.18126146495342255\n",
      "Iter: 350 \tLoss: 0.2130364328622818\n",
      "Iter: 360 \tLoss: 0.21064472198486328\n",
      "Iter: 370 \tLoss: 0.26688578724861145\n",
      "Iter: 380 \tLoss: 0.15113012492656708\n",
      "Iter: 390 \tLoss: 0.25521132349967957\n",
      "Iter: 400 \tLoss: 0.19636303186416626\n",
      "Iter: 410 \tLoss: 0.36770713329315186\n",
      "Iter: 420 \tLoss: 0.22383837401866913\n",
      "Iter: 430 \tLoss: 0.20818544924259186\n",
      "Iter: 440 \tLoss: 0.17050060629844666\n",
      "Mean Train Loss: 0.239812\n",
      "\n",
      "Val Loss: 0.387964 \tValidation Accuracy: 0.8707\n",
      "Epoch: 9\n",
      "Iter: 0 \tLoss: 0.2239312082529068\n",
      "Iter: 10 \tLoss: 0.2004595547914505\n",
      "Iter: 20 \tLoss: 0.16960015892982483\n",
      "Iter: 30 \tLoss: 0.18266607820987701\n",
      "Iter: 40 \tLoss: 0.23008674383163452\n",
      "Iter: 50 \tLoss: 0.21798835694789886\n",
      "Iter: 60 \tLoss: 0.1992763876914978\n",
      "Iter: 70 \tLoss: 0.2054784893989563\n",
      "Iter: 80 \tLoss: 0.23375511169433594\n",
      "Iter: 90 \tLoss: 0.34327101707458496\n",
      "Iter: 100 \tLoss: 0.19770076870918274\n",
      "Iter: 110 \tLoss: 0.15233966708183289\n",
      "Iter: 120 \tLoss: 0.2308323234319687\n",
      "Iter: 130 \tLoss: 0.30087918043136597\n",
      "Iter: 140 \tLoss: 0.14910002052783966\n",
      "Iter: 150 \tLoss: 0.22263872623443604\n",
      "Iter: 160 \tLoss: 0.2044728696346283\n",
      "Iter: 170 \tLoss: 0.22838211059570312\n",
      "Iter: 180 \tLoss: 0.19114474952220917\n",
      "Iter: 190 \tLoss: 0.3584274351596832\n",
      "Iter: 200 \tLoss: 0.259672611951828\n",
      "Iter: 210 \tLoss: 0.21366967260837555\n",
      "Iter: 220 \tLoss: 0.2491556704044342\n",
      "Iter: 230 \tLoss: 0.194650337100029\n",
      "Iter: 240 \tLoss: 0.23496147990226746\n",
      "Iter: 250 \tLoss: 0.2514927387237549\n",
      "Iter: 260 \tLoss: 0.20401015877723694\n",
      "Iter: 270 \tLoss: 0.2423221617937088\n",
      "Iter: 280 \tLoss: 0.1614241898059845\n",
      "Iter: 290 \tLoss: 0.19755195081233978\n",
      "Iter: 300 \tLoss: 0.21467745304107666\n",
      "Iter: 310 \tLoss: 0.23832033574581146\n",
      "Iter: 320 \tLoss: 0.19865421950817108\n",
      "Iter: 330 \tLoss: 0.23380228877067566\n",
      "Iter: 340 \tLoss: 0.21061649918556213\n",
      "Iter: 350 \tLoss: 0.2607533633708954\n",
      "Iter: 360 \tLoss: 0.2361699342727661\n",
      "Iter: 370 \tLoss: 0.25334346294403076\n",
      "Iter: 380 \tLoss: 0.2144843488931656\n",
      "Iter: 390 \tLoss: 0.2663695514202118\n",
      "Iter: 400 \tLoss: 0.28249457478523254\n",
      "Iter: 410 \tLoss: 0.287832111120224\n",
      "Iter: 420 \tLoss: 0.20560243725776672\n",
      "Iter: 430 \tLoss: 0.19198644161224365\n",
      "Iter: 440 \tLoss: 0.2747804820537567\n",
      "Mean Train Loss: 0.223553\n",
      "\n",
      "Epoch: 10\n",
      "Iter: 0 \tLoss: 0.2222309559583664\n",
      "Iter: 10 \tLoss: 0.2348138988018036\n",
      "Iter: 20 \tLoss: 0.181662917137146\n",
      "Iter: 30 \tLoss: 0.1590537130832672\n",
      "Iter: 40 \tLoss: 0.16230179369449615\n",
      "Iter: 50 \tLoss: 0.2247922122478485\n",
      "Iter: 60 \tLoss: 0.23376576602458954\n",
      "Iter: 70 \tLoss: 0.18990851938724518\n",
      "Iter: 80 \tLoss: 0.1807480752468109\n",
      "Iter: 90 \tLoss: 0.20196807384490967\n",
      "Iter: 100 \tLoss: 0.16760951280593872\n",
      "Iter: 110 \tLoss: 0.18275022506713867\n",
      "Iter: 120 \tLoss: 0.21422351896762848\n",
      "Iter: 130 \tLoss: 0.1704898625612259\n",
      "Iter: 140 \tLoss: 0.2373143434524536\n",
      "Iter: 150 \tLoss: 0.2326134890317917\n",
      "Iter: 160 \tLoss: 0.18013031780719757\n",
      "Iter: 170 \tLoss: 0.30657047033309937\n",
      "Iter: 180 \tLoss: 0.22302889823913574\n",
      "Iter: 190 \tLoss: 0.22016726434230804\n",
      "Iter: 200 \tLoss: 0.19752223789691925\n",
      "Iter: 210 \tLoss: 0.16978766024112701\n",
      "Iter: 220 \tLoss: 0.1758313626050949\n",
      "Iter: 230 \tLoss: 0.242891326546669\n",
      "Iter: 240 \tLoss: 0.1520039141178131\n",
      "Iter: 250 \tLoss: 0.23276640474796295\n",
      "Iter: 260 \tLoss: 0.20052951574325562\n",
      "Iter: 270 \tLoss: 0.20302583277225494\n",
      "Iter: 280 \tLoss: 0.29236215353012085\n",
      "Iter: 290 \tLoss: 0.2627364993095398\n",
      "Iter: 300 \tLoss: 0.2530781924724579\n",
      "Iter: 310 \tLoss: 0.2011946588754654\n",
      "Iter: 320 \tLoss: 0.15322571992874146\n",
      "Iter: 330 \tLoss: 0.17478547990322113\n",
      "Iter: 340 \tLoss: 0.19068960845470428\n",
      "Iter: 350 \tLoss: 0.18191096186637878\n",
      "Iter: 360 \tLoss: 0.24210821092128754\n",
      "Iter: 370 \tLoss: 0.24737541377544403\n",
      "Iter: 380 \tLoss: 0.2171233743429184\n",
      "Iter: 390 \tLoss: 0.23343399167060852\n",
      "Iter: 400 \tLoss: 0.2683562934398651\n",
      "Iter: 410 \tLoss: 0.22097687423229218\n",
      "Iter: 420 \tLoss: 0.2803998291492462\n",
      "Iter: 430 \tLoss: 0.20953382551670074\n",
      "Iter: 440 \tLoss: 0.22849197685718536\n",
      "Mean Train Loss: 0.210712\n",
      "\n",
      "Val Loss: 0.404798 \tValidation Accuracy: 0.8693\n",
      "Epoch: 11\n",
      "Iter: 0 \tLoss: 0.17326970398426056\n",
      "Iter: 10 \tLoss: 0.16375789046287537\n",
      "Iter: 20 \tLoss: 0.21620234847068787\n",
      "Iter: 30 \tLoss: 0.14653119444847107\n",
      "Iter: 40 \tLoss: 0.18728359043598175\n",
      "Iter: 50 \tLoss: 0.21104837954044342\n",
      "Iter: 60 \tLoss: 0.2109764963388443\n",
      "Iter: 70 \tLoss: 0.19037146866321564\n",
      "Iter: 80 \tLoss: 0.2351674884557724\n",
      "Iter: 90 \tLoss: 0.19006168842315674\n",
      "Iter: 100 \tLoss: 0.181046262383461\n",
      "Iter: 110 \tLoss: 0.20366689562797546\n",
      "Iter: 120 \tLoss: 0.16717752814292908\n",
      "Iter: 130 \tLoss: 0.2119271159172058\n",
      "Iter: 140 \tLoss: 0.20435582101345062\n",
      "Iter: 150 \tLoss: 0.18541990220546722\n",
      "Iter: 160 \tLoss: 0.23392464220523834\n",
      "Iter: 170 \tLoss: 0.23811805248260498\n",
      "Iter: 180 \tLoss: 0.1866006702184677\n",
      "Iter: 190 \tLoss: 0.16344380378723145\n",
      "Iter: 200 \tLoss: 0.24778735637664795\n",
      "Iter: 210 \tLoss: 0.22698691487312317\n",
      "Iter: 220 \tLoss: 0.2705343961715698\n",
      "Iter: 230 \tLoss: 0.2340090125799179\n",
      "Iter: 240 \tLoss: 0.26772502064704895\n",
      "Iter: 250 \tLoss: 0.1456626057624817\n",
      "Iter: 260 \tLoss: 0.15724976360797882\n",
      "Iter: 270 \tLoss: 0.21868173778057098\n",
      "Iter: 280 \tLoss: 0.13958126306533813\n",
      "Iter: 290 \tLoss: 0.2725190222263336\n",
      "Iter: 300 \tLoss: 0.1538829654455185\n",
      "Iter: 310 \tLoss: 0.23070618510246277\n",
      "Iter: 320 \tLoss: 0.12225864827632904\n",
      "Iter: 330 \tLoss: 0.24705000221729279\n",
      "Iter: 340 \tLoss: 0.25180357694625854\n",
      "Iter: 350 \tLoss: 0.23712357878684998\n",
      "Iter: 360 \tLoss: 0.19159431755542755\n",
      "Iter: 370 \tLoss: 0.18996858596801758\n",
      "Iter: 380 \tLoss: 0.22700431942939758\n",
      "Iter: 390 \tLoss: 0.25076502561569214\n",
      "Iter: 400 \tLoss: 0.18959486484527588\n",
      "Iter: 410 \tLoss: 0.1962764859199524\n",
      "Iter: 420 \tLoss: 0.20066604018211365\n",
      "Iter: 430 \tLoss: 0.22135324776172638\n",
      "Iter: 440 \tLoss: 0.2719826400279999\n",
      "Mean Train Loss: 0.199226\n",
      "\n",
      "Epoch: 12\n",
      "Iter: 0 \tLoss: 0.1672920286655426\n",
      "Iter: 10 \tLoss: 0.15054602921009064\n",
      "Iter: 20 \tLoss: 0.17632150650024414\n",
      "Iter: 30 \tLoss: 0.18654198944568634\n",
      "Iter: 40 \tLoss: 0.15324066579341888\n",
      "Iter: 50 \tLoss: 0.17359018325805664\n",
      "Iter: 60 \tLoss: 0.1995309591293335\n",
      "Iter: 70 \tLoss: 0.23489166796207428\n",
      "Iter: 80 \tLoss: 0.17571060359477997\n",
      "Iter: 90 \tLoss: 0.21097402274608612\n",
      "Iter: 100 \tLoss: 0.2105875313282013\n",
      "Iter: 110 \tLoss: 0.15527412295341492\n",
      "Iter: 120 \tLoss: 0.21678243577480316\n",
      "Iter: 130 \tLoss: 0.22328545153141022\n",
      "Iter: 140 \tLoss: 0.1656034141778946\n",
      "Iter: 150 \tLoss: 0.20103974640369415\n",
      "Iter: 160 \tLoss: 0.13414748013019562\n",
      "Iter: 170 \tLoss: 0.23298397660255432\n",
      "Iter: 180 \tLoss: 0.1943044662475586\n",
      "Iter: 190 \tLoss: 0.14742639660835266\n",
      "Iter: 200 \tLoss: 0.24127836525440216\n",
      "Iter: 210 \tLoss: 0.23569846153259277\n",
      "Iter: 220 \tLoss: 0.2392844557762146\n",
      "Iter: 230 \tLoss: 0.15949536859989166\n",
      "Iter: 240 \tLoss: 0.17144253849983215\n",
      "Iter: 250 \tLoss: 0.13613831996917725\n",
      "Iter: 260 \tLoss: 0.11112591624259949\n",
      "Iter: 270 \tLoss: 0.2370321899652481\n",
      "Iter: 280 \tLoss: 0.19986219704151154\n",
      "Iter: 290 \tLoss: 0.21662184596061707\n",
      "Iter: 300 \tLoss: 0.20941871404647827\n",
      "Iter: 310 \tLoss: 0.22697070240974426\n",
      "Iter: 320 \tLoss: 0.1519564688205719\n",
      "Iter: 330 \tLoss: 0.20590822398662567\n",
      "Iter: 340 \tLoss: 0.16633671522140503\n",
      "Iter: 350 \tLoss: 0.24132947623729706\n",
      "Iter: 360 \tLoss: 0.14725467562675476\n",
      "Iter: 370 \tLoss: 0.2151261568069458\n",
      "Iter: 380 \tLoss: 0.20720437169075012\n",
      "Iter: 390 \tLoss: 0.15979157388210297\n",
      "Iter: 400 \tLoss: 0.15478357672691345\n",
      "Iter: 410 \tLoss: 0.15374499559402466\n",
      "Iter: 420 \tLoss: 0.14370863139629364\n",
      "Iter: 430 \tLoss: 0.18307806551456451\n",
      "Iter: 440 \tLoss: 0.17320378124713898\n",
      "Mean Train Loss: 0.187146\n",
      "\n",
      "Val Loss: 0.409396 \tValidation Accuracy: 0.8689\n",
      "Epoch: 13\n",
      "Iter: 0 \tLoss: 0.18302997946739197\n",
      "Iter: 10 \tLoss: 0.20626288652420044\n",
      "Iter: 20 \tLoss: 0.14642713963985443\n",
      "Iter: 30 \tLoss: 0.18488988280296326\n",
      "Iter: 40 \tLoss: 0.14229929447174072\n",
      "Iter: 50 \tLoss: 0.17162635922431946\n",
      "Iter: 60 \tLoss: 0.1267058104276657\n",
      "Iter: 70 \tLoss: 0.19421949982643127\n",
      "Iter: 80 \tLoss: 0.14760403335094452\n",
      "Iter: 90 \tLoss: 0.11674555391073227\n",
      "Iter: 100 \tLoss: 0.16782183945178986\n",
      "Iter: 110 \tLoss: 0.16658176481723785\n",
      "Iter: 120 \tLoss: 0.12828490138053894\n",
      "Iter: 130 \tLoss: 0.138467475771904\n",
      "Iter: 140 \tLoss: 0.11136098206043243\n",
      "Iter: 150 \tLoss: 0.2018074095249176\n",
      "Iter: 160 \tLoss: 0.15174223482608795\n",
      "Iter: 170 \tLoss: 0.17069785296916962\n",
      "Iter: 180 \tLoss: 0.21581368148326874\n",
      "Iter: 190 \tLoss: 0.1658654659986496\n",
      "Iter: 200 \tLoss: 0.18054531514644623\n",
      "Iter: 210 \tLoss: 0.24070855975151062\n",
      "Iter: 220 \tLoss: 0.15552525222301483\n",
      "Iter: 230 \tLoss: 0.10055959224700928\n",
      "Iter: 240 \tLoss: 0.18247082829475403\n",
      "Iter: 250 \tLoss: 0.17821505665779114\n",
      "Iter: 260 \tLoss: 0.16922402381896973\n",
      "Iter: 270 \tLoss: 0.15991054475307465\n",
      "Iter: 280 \tLoss: 0.21300365030765533\n",
      "Iter: 290 \tLoss: 0.15262332558631897\n",
      "Iter: 300 \tLoss: 0.16775745153427124\n",
      "Iter: 310 \tLoss: 0.20195797085762024\n",
      "Iter: 320 \tLoss: 0.18836534023284912\n",
      "Iter: 330 \tLoss: 0.22056861221790314\n",
      "Iter: 340 \tLoss: 0.21282748878002167\n",
      "Iter: 350 \tLoss: 0.17075692117214203\n",
      "Iter: 360 \tLoss: 0.19734035432338715\n",
      "Iter: 370 \tLoss: 0.17914995551109314\n",
      "Iter: 380 \tLoss: 0.1770297735929489\n",
      "Iter: 390 \tLoss: 0.2132992297410965\n",
      "Iter: 400 \tLoss: 0.2128065824508667\n",
      "Iter: 410 \tLoss: 0.17628751695156097\n",
      "Iter: 420 \tLoss: 0.18373358249664307\n",
      "Iter: 430 \tLoss: 0.19918586313724518\n",
      "Iter: 440 \tLoss: 0.235993430018425\n",
      "Mean Train Loss: 0.175470\n",
      "\n",
      "Epoch: 14\n",
      "Iter: 0 \tLoss: 0.14022138714790344\n",
      "Iter: 10 \tLoss: 0.19993872940540314\n",
      "Iter: 20 \tLoss: 0.1480305939912796\n",
      "Iter: 30 \tLoss: 0.14763307571411133\n",
      "Iter: 40 \tLoss: 0.15646646916866302\n",
      "Iter: 50 \tLoss: 0.1838291734457016\n",
      "Iter: 60 \tLoss: 0.1522427648305893\n",
      "Iter: 70 \tLoss: 0.13256262242794037\n",
      "Iter: 80 \tLoss: 0.17466145753860474\n",
      "Iter: 90 \tLoss: 0.16667166352272034\n",
      "Iter: 100 \tLoss: 0.13186445832252502\n",
      "Iter: 110 \tLoss: 0.1356903612613678\n",
      "Iter: 120 \tLoss: 0.1791737973690033\n",
      "Iter: 130 \tLoss: 0.19955600798130035\n",
      "Iter: 140 \tLoss: 0.17251302301883698\n",
      "Iter: 150 \tLoss: 0.25220349431037903\n",
      "Iter: 160 \tLoss: 0.15314729511737823\n",
      "Iter: 170 \tLoss: 0.113298200070858\n",
      "Iter: 180 \tLoss: 0.1832338273525238\n",
      "Iter: 190 \tLoss: 0.17975425720214844\n",
      "Iter: 200 \tLoss: 0.1663646548986435\n",
      "Iter: 210 \tLoss: 0.15505020320415497\n",
      "Iter: 220 \tLoss: 0.18857888877391815\n",
      "Iter: 230 \tLoss: 0.14856673777103424\n",
      "Iter: 240 \tLoss: 0.20441262423992157\n",
      "Iter: 250 \tLoss: 0.18343578279018402\n",
      "Iter: 260 \tLoss: 0.13265913724899292\n",
      "Iter: 270 \tLoss: 0.17367321252822876\n",
      "Iter: 280 \tLoss: 0.14733488857746124\n",
      "Iter: 290 \tLoss: 0.11039029061794281\n",
      "Iter: 300 \tLoss: 0.1505914181470871\n",
      "Iter: 310 \tLoss: 0.22748589515686035\n",
      "Iter: 320 \tLoss: 0.21057717502117157\n",
      "Iter: 330 \tLoss: 0.22232259809970856\n",
      "Iter: 340 \tLoss: 0.19013890624046326\n",
      "Iter: 350 \tLoss: 0.1696344017982483\n",
      "Iter: 360 \tLoss: 0.16971313953399658\n",
      "Iter: 370 \tLoss: 0.2503366768360138\n",
      "Iter: 380 \tLoss: 0.20586606860160828\n",
      "Iter: 390 \tLoss: 0.21591347455978394\n",
      "Iter: 400 \tLoss: 0.19500067830085754\n",
      "Iter: 410 \tLoss: 0.22177475690841675\n",
      "Iter: 420 \tLoss: 0.16781403124332428\n",
      "Iter: 430 \tLoss: 0.18324705958366394\n",
      "Iter: 440 \tLoss: 0.19459021091461182\n",
      "Mean Train Loss: 0.167021\n",
      "\n",
      "Val Loss: 0.453847 \tValidation Accuracy: 0.8616\n",
      "Epoch: 15\n",
      "Iter: 0 \tLoss: 0.1527436077594757\n",
      "Iter: 10 \tLoss: 0.15756410360336304\n",
      "Iter: 20 \tLoss: 0.14007073640823364\n",
      "Iter: 30 \tLoss: 0.16531726717948914\n",
      "Iter: 40 \tLoss: 0.13881178200244904\n",
      "Iter: 50 \tLoss: 0.12199026346206665\n",
      "Iter: 60 \tLoss: 0.17379173636436462\n",
      "Iter: 70 \tLoss: 0.15155290067195892\n",
      "Iter: 80 \tLoss: 0.16765102744102478\n",
      "Iter: 90 \tLoss: 0.12579262256622314\n",
      "Iter: 100 \tLoss: 0.11217518895864487\n",
      "Iter: 110 \tLoss: 0.1779855638742447\n",
      "Iter: 120 \tLoss: 0.21448959410190582\n",
      "Iter: 130 \tLoss: 0.17395968735218048\n",
      "Iter: 140 \tLoss: 0.14993678033351898\n",
      "Iter: 150 \tLoss: 0.19898419082164764\n",
      "Iter: 160 \tLoss: 0.15119421482086182\n",
      "Iter: 170 \tLoss: 0.19144533574581146\n",
      "Iter: 180 \tLoss: 0.1819283813238144\n",
      "Iter: 190 \tLoss: 0.15967096388339996\n",
      "Iter: 200 \tLoss: 0.16624204814434052\n",
      "Iter: 210 \tLoss: 0.1289658546447754\n",
      "Iter: 220 \tLoss: 0.1597583144903183\n",
      "Iter: 230 \tLoss: 0.14895455539226532\n",
      "Iter: 240 \tLoss: 0.14110693335533142\n",
      "Iter: 250 \tLoss: 0.2123284935951233\n",
      "Iter: 260 \tLoss: 0.11240878701210022\n",
      "Iter: 270 \tLoss: 0.15717504918575287\n",
      "Iter: 280 \tLoss: 0.15527960658073425\n",
      "Iter: 290 \tLoss: 0.2197834998369217\n",
      "Iter: 300 \tLoss: 0.11506611853837967\n",
      "Iter: 310 \tLoss: 0.17604398727416992\n",
      "Iter: 320 \tLoss: 0.20499584078788757\n",
      "Iter: 330 \tLoss: 0.18130740523338318\n",
      "Iter: 340 \tLoss: 0.13733112812042236\n",
      "Iter: 350 \tLoss: 0.17683301866054535\n",
      "Iter: 360 \tLoss: 0.18500187993049622\n",
      "Iter: 370 \tLoss: 0.19477154314517975\n",
      "Iter: 380 \tLoss: 0.1565878689289093\n",
      "Iter: 390 \tLoss: 0.18764783442020416\n",
      "Iter: 400 \tLoss: 0.21726977825164795\n",
      "Iter: 410 \tLoss: 0.17070838809013367\n",
      "Iter: 420 \tLoss: 0.2087656706571579\n",
      "Iter: 430 \tLoss: 0.17353786528110504\n",
      "Iter: 440 \tLoss: 0.17647598683834076\n",
      "Mean Train Loss: 0.158495\n",
      "\n",
      "Epoch: 16\n",
      "Iter: 0 \tLoss: 0.20620097219944\n",
      "Iter: 10 \tLoss: 0.15111814439296722\n",
      "Iter: 20 \tLoss: 0.1423458755016327\n",
      "Iter: 30 \tLoss: 0.15653455257415771\n",
      "Iter: 40 \tLoss: 0.10763952881097794\n",
      "Iter: 50 \tLoss: 0.18115875124931335\n",
      "Iter: 60 \tLoss: 0.12333757430315018\n",
      "Iter: 70 \tLoss: 0.12939795851707458\n",
      "Iter: 80 \tLoss: 0.15892279148101807\n",
      "Iter: 90 \tLoss: 0.10524044185876846\n",
      "Iter: 100 \tLoss: 0.15351590514183044\n",
      "Iter: 110 \tLoss: 0.14796870946884155\n",
      "Iter: 120 \tLoss: 0.12697017192840576\n",
      "Iter: 130 \tLoss: 0.16648519039154053\n",
      "Iter: 140 \tLoss: 0.15105748176574707\n",
      "Iter: 150 \tLoss: 0.14476855099201202\n",
      "Iter: 160 \tLoss: 0.12809476256370544\n",
      "Iter: 170 \tLoss: 0.1629602462053299\n",
      "Iter: 180 \tLoss: 0.14975480735301971\n",
      "Iter: 190 \tLoss: 0.13158594071865082\n",
      "Iter: 200 \tLoss: 0.17301596701145172\n",
      "Iter: 210 \tLoss: 0.13357923924922943\n",
      "Iter: 220 \tLoss: 0.15640971064567566\n",
      "Iter: 230 \tLoss: 0.10992461442947388\n",
      "Iter: 240 \tLoss: 0.16587521135807037\n",
      "Iter: 250 \tLoss: 0.13771505653858185\n",
      "Iter: 260 \tLoss: 0.12872086465358734\n",
      "Iter: 270 \tLoss: 0.13441403210163116\n",
      "Iter: 280 \tLoss: 0.15225474536418915\n",
      "Iter: 290 \tLoss: 0.15063050389289856\n",
      "Iter: 300 \tLoss: 0.1435546576976776\n",
      "Iter: 310 \tLoss: 0.1435035914182663\n",
      "Iter: 320 \tLoss: 0.18228496611118317\n",
      "Iter: 330 \tLoss: 0.1981697380542755\n",
      "Iter: 340 \tLoss: 0.17002622783184052\n",
      "Iter: 350 \tLoss: 0.1769547313451767\n",
      "Iter: 360 \tLoss: 0.14937655627727509\n",
      "Iter: 370 \tLoss: 0.16868245601654053\n",
      "Iter: 380 \tLoss: 0.11261619627475739\n",
      "Iter: 390 \tLoss: 0.19327442348003387\n",
      "Iter: 400 \tLoss: 0.13469481468200684\n",
      "Iter: 410 \tLoss: 0.09925263375043869\n",
      "Iter: 420 \tLoss: 0.11152779310941696\n",
      "Iter: 430 \tLoss: 0.12851564586162567\n",
      "Iter: 440 \tLoss: 0.11411915719509125\n",
      "Mean Train Loss: 0.149827\n",
      "\n",
      "Val Loss: 0.483934 \tValidation Accuracy: 0.8674\n",
      "Epoch: 17\n",
      "Iter: 0 \tLoss: 0.12418723106384277\n",
      "Iter: 10 \tLoss: 0.10545649379491806\n",
      "Iter: 20 \tLoss: 0.12968343496322632\n",
      "Iter: 30 \tLoss: 0.12184470146894455\n",
      "Iter: 40 \tLoss: 0.11179184913635254\n",
      "Iter: 50 \tLoss: 0.11817961931228638\n",
      "Iter: 60 \tLoss: 0.14024516940116882\n",
      "Iter: 70 \tLoss: 0.1557568460702896\n",
      "Iter: 80 \tLoss: 0.11294269561767578\n",
      "Iter: 90 \tLoss: 0.15559282898902893\n",
      "Iter: 100 \tLoss: 0.1739923059940338\n",
      "Iter: 110 \tLoss: 0.11204507946968079\n",
      "Iter: 120 \tLoss: 0.15327975153923035\n",
      "Iter: 130 \tLoss: 0.11373700946569443\n",
      "Iter: 140 \tLoss: 0.1349170207977295\n",
      "Iter: 150 \tLoss: 0.1572328358888626\n",
      "Iter: 160 \tLoss: 0.10383011400699615\n",
      "Iter: 170 \tLoss: 0.1015603244304657\n",
      "Iter: 180 \tLoss: 0.12042369693517685\n",
      "Iter: 190 \tLoss: 0.11252225190401077\n",
      "Iter: 200 \tLoss: 0.11292252689599991\n",
      "Iter: 210 \tLoss: 0.14183129370212555\n",
      "Iter: 220 \tLoss: 0.16807956993579865\n",
      "Iter: 230 \tLoss: 0.11020788550376892\n",
      "Iter: 240 \tLoss: 0.1345779150724411\n",
      "Iter: 250 \tLoss: 0.10372387617826462\n",
      "Iter: 260 \tLoss: 0.11568140983581543\n",
      "Iter: 270 \tLoss: 0.1886996477842331\n",
      "Iter: 280 \tLoss: 0.12405797094106674\n",
      "Iter: 290 \tLoss: 0.14177267253398895\n",
      "Iter: 300 \tLoss: 0.16784197092056274\n",
      "Iter: 310 \tLoss: 0.14138475060462952\n",
      "Iter: 320 \tLoss: 0.1461772471666336\n",
      "Iter: 330 \tLoss: 0.16875407099723816\n",
      "Iter: 340 \tLoss: 0.1581360548734665\n",
      "Iter: 350 \tLoss: 0.13258762657642365\n",
      "Iter: 360 \tLoss: 0.15563571453094482\n",
      "Iter: 370 \tLoss: 0.09870004653930664\n",
      "Iter: 380 \tLoss: 0.1459112912416458\n",
      "Iter: 390 \tLoss: 0.18781979382038116\n",
      "Iter: 400 \tLoss: 0.2769262492656708\n",
      "Iter: 410 \tLoss: 0.16654641926288605\n",
      "Iter: 420 \tLoss: 0.18532855808734894\n",
      "Iter: 430 \tLoss: 0.14040690660476685\n",
      "Iter: 440 \tLoss: 0.14605534076690674\n",
      "Mean Train Loss: 0.141904\n",
      "\n",
      "Epoch: 18\n",
      "Iter: 0 \tLoss: 0.11139245331287384\n",
      "Iter: 10 \tLoss: 0.10566635429859161\n",
      "Iter: 20 \tLoss: 0.10713545978069305\n",
      "Iter: 30 \tLoss: 0.09536517411470413\n",
      "Iter: 40 \tLoss: 0.1825188398361206\n",
      "Iter: 50 \tLoss: 0.09896507114171982\n",
      "Iter: 60 \tLoss: 0.13149484992027283\n",
      "Iter: 70 \tLoss: 0.13230854272842407\n",
      "Iter: 80 \tLoss: 0.1731114238500595\n",
      "Iter: 90 \tLoss: 0.15577100217342377\n",
      "Iter: 100 \tLoss: 0.12776444852352142\n",
      "Iter: 110 \tLoss: 0.15076610445976257\n",
      "Iter: 120 \tLoss: 0.14513851702213287\n",
      "Iter: 130 \tLoss: 0.13207869231700897\n",
      "Iter: 140 \tLoss: 0.142032191157341\n",
      "Iter: 150 \tLoss: 0.12225627154111862\n",
      "Iter: 160 \tLoss: 0.13160228729248047\n",
      "Iter: 170 \tLoss: 0.10187716782093048\n",
      "Iter: 180 \tLoss: 0.14734070003032684\n",
      "Iter: 190 \tLoss: 0.2077006995677948\n",
      "Iter: 200 \tLoss: 0.14354188740253448\n",
      "Iter: 210 \tLoss: 0.1337861865758896\n",
      "Iter: 220 \tLoss: 0.12076921761035919\n",
      "Iter: 230 \tLoss: 0.11288855969905853\n",
      "Iter: 240 \tLoss: 0.09829845279455185\n",
      "Iter: 250 \tLoss: 0.12413065135478973\n",
      "Iter: 260 \tLoss: 0.1438979208469391\n",
      "Iter: 270 \tLoss: 0.1888720840215683\n",
      "Iter: 280 \tLoss: 0.1495230346918106\n",
      "Iter: 290 \tLoss: 0.19109219312667847\n",
      "Iter: 300 \tLoss: 0.17614540457725525\n",
      "Iter: 310 \tLoss: 0.1091761589050293\n",
      "Iter: 320 \tLoss: 0.12610310316085815\n",
      "Iter: 330 \tLoss: 0.13356666266918182\n",
      "Iter: 340 \tLoss: 0.16781331598758698\n",
      "Iter: 350 \tLoss: 0.16094769537448883\n",
      "Iter: 360 \tLoss: 0.18885672092437744\n",
      "Iter: 370 \tLoss: 0.17356441915035248\n",
      "Iter: 380 \tLoss: 0.15060415863990784\n",
      "Iter: 390 \tLoss: 0.14451207220554352\n",
      "Iter: 400 \tLoss: 0.15269894897937775\n",
      "Iter: 410 \tLoss: 0.1931159794330597\n",
      "Iter: 420 \tLoss: 0.13051749765872955\n",
      "Iter: 430 \tLoss: 0.12853477895259857\n",
      "Iter: 440 \tLoss: 0.15451662242412567\n",
      "Mean Train Loss: 0.136050\n",
      "\n",
      "Val Loss: 0.524928 \tValidation Accuracy: 0.8606\n",
      "Epoch: 19\n",
      "Iter: 0 \tLoss: 0.08369746804237366\n",
      "Iter: 10 \tLoss: 0.13961131870746613\n",
      "Iter: 20 \tLoss: 0.12724314630031586\n",
      "Iter: 30 \tLoss: 0.12991243600845337\n",
      "Iter: 40 \tLoss: 0.15009145438671112\n",
      "Iter: 50 \tLoss: 0.13095708191394806\n",
      "Iter: 60 \tLoss: 0.09543324261903763\n",
      "Iter: 70 \tLoss: 0.13016340136528015\n",
      "Iter: 80 \tLoss: 0.10806658118963242\n",
      "Iter: 90 \tLoss: 0.1249196007847786\n",
      "Iter: 100 \tLoss: 0.12469065189361572\n",
      "Iter: 110 \tLoss: 0.09523186832666397\n",
      "Iter: 120 \tLoss: 0.13431109488010406\n",
      "Iter: 130 \tLoss: 0.1199861615896225\n",
      "Iter: 140 \tLoss: 0.15408991277217865\n",
      "Iter: 150 \tLoss: 0.08802083879709244\n",
      "Iter: 160 \tLoss: 0.09733349829912186\n",
      "Iter: 170 \tLoss: 0.1095767468214035\n",
      "Iter: 180 \tLoss: 0.11184115707874298\n",
      "Iter: 190 \tLoss: 0.15676502883434296\n",
      "Iter: 200 \tLoss: 0.09722263365983963\n",
      "Iter: 210 \tLoss: 0.17729498445987701\n",
      "Iter: 220 \tLoss: 0.16298212110996246\n",
      "Iter: 230 \tLoss: 0.13970965147018433\n",
      "Iter: 240 \tLoss: 0.12360535562038422\n",
      "Iter: 250 \tLoss: 0.15075720846652985\n",
      "Iter: 260 \tLoss: 0.13568876683712006\n",
      "Iter: 270 \tLoss: 0.09342999011278152\n",
      "Iter: 280 \tLoss: 0.14807429909706116\n",
      "Iter: 290 \tLoss: 0.1308525949716568\n",
      "Iter: 300 \tLoss: 0.11634425073862076\n",
      "Iter: 310 \tLoss: 0.08731549233198166\n",
      "Iter: 320 \tLoss: 0.15344110131263733\n",
      "Iter: 330 \tLoss: 0.12819154560565948\n",
      "Iter: 340 \tLoss: 0.1806424856185913\n",
      "Iter: 350 \tLoss: 0.11727286130189896\n",
      "Iter: 360 \tLoss: 0.15415140986442566\n",
      "Iter: 370 \tLoss: 0.14155949652194977\n",
      "Iter: 380 \tLoss: 0.18569226562976837\n",
      "Iter: 390 \tLoss: 0.10659501701593399\n",
      "Iter: 400 \tLoss: 0.0930059477686882\n",
      "Iter: 410 \tLoss: 0.1464458853006363\n",
      "Iter: 420 \tLoss: 0.100596122443676\n",
      "Iter: 430 \tLoss: 0.15501555800437927\n",
      "Iter: 440 \tLoss: 0.12162138521671295\n",
      "Mean Train Loss: 0.127238\n",
      "\n",
      "Best Validation Accuracy: 0.8707\n",
      "Val Loss: 0.540924 \tValidation Accuracy: 0.8653\n",
      "Accuracy: 0.8707446808510638\n"
     ]
    }
   ],
   "source": [
    "model = CNN(47)                # создаем модель 47 классов которые надо распознать (mapping) \n",
    "loss_f = nn.CrossEntropyLoss() # фиксируем Loss\n",
    "#loss_f = nn.NLLLoss() #  другие функции потерь\n",
    "#loss_f =nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-1) # применяем оптимизатор\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "n_epoch = 20 # кол-во эпох\n",
    "val_fre = 2  # как часто делаем валидацию\n",
    "\n",
    "train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model, val_loader)\n",
    "print(f'Accuracy: {best_val_accuracy}')\n",
    "# ошибки Val Loss: уменьшаются,  точность \tAccuracy: растет - модель обучается \n",
    "# (обучение может остановится и даже пойти переобучение Val Loss растет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "112ee911-2610-4f5d-84b4-5f492a12f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8707446808510638\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {best_val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c1d76-cfef-4cb5-8f3d-667e534a1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=1000             Val Loss: 0.471095 \tAccuracy: 0.8432978723404255\n",
    "# batch_size=512              Val Loss: 0.444851 \tAccuracy: 0.8554787234042553\n",
    "# batch_size=512 +1слойLinear_64 Val Loss: 0.441709 Accuracy: 0.8507446808510638\n",
    "# batch_size=512 + nn.NLLLoss Val Loss: nan \t    Accuracy: 0.02127659574468085\n",
    "# batch_size=256 features=64  Val Loss: 0.565492 \tAccuracy: 0.8465425531914894\n",
    "# batch_size=512 Normalize([0.1307], [0.3081]) Val Loss: 0.469646 \tAccuracy: 0.8529787234042553\n",
    "# batch_size=512 + слой dilation=2, padding=2       Accuracy: 0.8661170212765957\n",
    "# batch_size=512 + torch.optim.Adam                 Accuracy: 0.8668617021276596\n",
    "# batch_size=256 + torch.optim.Adam + Normalize     Accuracy: 0.8698404255319149\n",
    "# batch_size=256 + torch.optim.Adam + Normalize + Linear Accuracy: 0.8707446808510638!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703e227-fadd-4631-9df7-f9b52f517fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем директорию для сохранения весов\n",
    "import os\n",
    "os.makedirs('checkpoints/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53594048-9b1f-4b49-966e-183a56fa52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoints/cnn.pth')# сохраняем веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30d02f-58b9-4729-a439-c38cffbdea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/cnn.pth'))# прикручиваем к ней словарь с весами и смотрим метрики\n",
    "validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6aa71-40e2-4d1a-95da-fecfdd273cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель сохраняем в ф-л model.pkl\n",
    "with open(os.path.join('myapp', 'model.pkl'),'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3f5c3-f9d3-41bc-804e-6dafa0434908",
   "metadata": {},
   "source": [
    "Вы можете заметить, что рукописные символы распознаются хуже, чем картинки из датасета. При желании попробуйте приблизить их к тем, на которых училась ваша модель. Возможно, вам пригодятся фильтры: Eroding and Dilating и Smoothing Images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
